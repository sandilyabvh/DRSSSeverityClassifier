{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VVnQ6fc81thx",
        "outputId": "fc5b1939-f339-4752-c9ee-d1cac4c7ce92"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "8gcCTRZ2vQPE"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import transforms\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image, ImageEnhance\n",
        "import argparse\n",
        "import os\n",
        "import copy\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.models import resnet18\n",
        "from pprint import pprint\n",
        "from sklearn.metrics import balanced_accuracy_score\n",
        "from sklearn.metrics import f1_score\n",
        "import cv2\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "LABELS_Severity = {35: 0,\n",
        "                   43: 0,\n",
        "                   47: 1,\n",
        "                   53: 1,\n",
        "                   61: 2,\n",
        "                   65: 2,\n",
        "                   71: 2,\n",
        "                   85: 2}\n",
        "\n",
        "\n",
        "mean = (.1706)\n",
        "std = (.2112)\n",
        "normalize = transforms.Normalize(mean=mean, std=std)\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Grayscale(num_output_channels=1),\n",
        "    transforms.Resize(size=(224,224)),\n",
        "    transforms.ToTensor(),\n",
        "    normalize,\n",
        "])\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Grayscale(num_output_channels=1),\n",
        "    transforms.Resize(size=(224,224)),\n",
        "    transforms.ToTensor(),\n",
        "    normalize,\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class OCTDataset(Dataset):\n",
        "    def __init__(self, annot=None, subset='train', transform=None, device='cpu'):\n",
        "        if subset == 'train':\n",
        "            self.annot = pd.read_csv(\"/content/drive/MyDrive/FML_Project/df_prime_train.csv\")                      \n",
        "        elif subset == 'test':\n",
        "            self.annot = pd.read_csv(\"/content/drive/MyDrive/FML_Project/df_prime_test.csv\")\n",
        "\n",
        "        # Extract \"Patient_ID\" and \"Week_Num\" columns\n",
        "        self.patient_ids = self.annot[\"Patient_ID\"]\n",
        "        self.week_nums = self.annot[\"Week_Num\"]\n",
        "        self.patient_ids = self.annot[\"Patient_ID\"]\n",
        "        self.annot['Severity_Label'] = [LABELS_Severity[drss] for drss in copy.deepcopy(self.annot['DRSS'].values)]\n",
        "        self.drss_class = self.annot['Severity_Label']\n",
        "\n",
        "        # Create unique pairs of values\n",
        "        self.unique_pairs = set(zip(self.patient_ids, self.week_nums, self.drss_class))\n",
        "\n",
        "        self.root = os.path.expanduser(\"/content/drive/MyDrive/FML_Project/\")\n",
        "        self.transform = transform\n",
        "        self.nb_classes=len(np.unique(list(LABELS_Severity.values())))\n",
        "        self.path_list = self.annot['File_Path'].values\n",
        "\n",
        "        self._labels = [pair[2] for pair in self.unique_pairs]\n",
        "        assert len(self.unique_pairs) == len(self._labels)\n",
        "        \n",
        "        max_samples = int(len(self._labels)) #32 #int(len(self._labels)/2)\n",
        "        self.max_samples = max_samples\n",
        "        self.device = device\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        # Get the Patient_ID and Week_Num from the indexed element in unique_pairs\n",
        "        patient_id, week_num, target = list(self.unique_pairs)[index]\n",
        "\n",
        "        # Filter the annot DataFrame to select rows that match the Patient_ID and Week_Num\n",
        "        filtered_df = self.annot[(self.annot['Patient_ID'] == patient_id) & (self.annot['Week_Num'] == week_num)]\n",
        "\n",
        "        # Extract the file paths from the filtered DataFrame and return them as a list\n",
        "        file_paths = [self.root + file_path for file_path in filtered_df['File_Path'].values.tolist()]\n",
        "        image_path = os.path.dirname(file_paths[0])+\"/fused_image.jpg\"\n",
        "        # image_path = os.path.dirname(file_paths[0])+\"/cn_final.jpg\"\n",
        "        # image_path = os.path.dirname(file_paths[0])+\"/ab_final.png\"\n",
        "        # image_path = os.path.dirname(file_paths[0])+\"/grid_image.jpg\"\n",
        "        # image_path = os.path.dirname(file_paths[0])+\"/grid_image_canny.jpg\"\n",
        "\n",
        "        img = Image.open(image_path)\n",
        "        img_gray = img.convert(\"L\")\n",
        "\n",
        "        if self.transform is not None:\n",
        "            img_sharpened = self.transform(img_gray)\n",
        "        \n",
        "        return img_sharpened, target\n",
        "\n",
        "    def __len__(self):\n",
        "        if self.max_samples is not None:\n",
        "            return min(len(self._labels), self.max_samples)\n",
        "        else:\n",
        "            return len(self._labels)    "
      ],
      "metadata": {
        "id": "7mfdBlaJxA1k"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#set up the device (GPU or CPU)\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print('Found device:', device)\n",
        "\n",
        "trainset = OCTDataset(subset='train', transform=train_transform, device=device)\n",
        "\n",
        "#define the hyperparameters\n",
        "batch_size = 32\n",
        "\n",
        "trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "print('Train and Test loader complete')"
      ],
      "metadata": {
        "id": "GBg-GBBnv6ZW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13582281-6527-4932-c60c-d5a96b98109a"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found device: cuda:0\n",
            "Train and Test loader complete\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the Gaussian Naive Bayes classifier\n",
        "clf = GaussianNB()\n",
        "\n",
        "# Train the classifier\n",
        "train_features, train_labels = [], []\n",
        "for i, (inputs, labels) in enumerate(trainloader):\n",
        "    train_features.extend(inputs.view(inputs.shape[0], -1).numpy())\n",
        "    train_labels.extend(labels.numpy())\n",
        "\n",
        "train_features, train_labels = np.array(train_features), np.array(train_labels)\n",
        "clf.fit(train_features, train_labels)"
      ],
      "metadata": {
        "id": "XRSYemgawDHv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "f16f6ab7-7a18-4b7b-fdf3-b6c254bcb182"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GaussianNB()"
            ],
            "text/html": [
              "<style>#sk-container-id-10 {color: black;background-color: white;}#sk-container-id-10 pre{padding: 0;}#sk-container-id-10 div.sk-toggleable {background-color: white;}#sk-container-id-10 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-10 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-10 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-10 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-10 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-10 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-10 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-10 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-10 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-10 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-10 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-10 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-10 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-10 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-10 div.sk-item {position: relative;z-index: 1;}#sk-container-id-10 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-10 div.sk-item::before, #sk-container-id-10 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-10 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-10 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-10 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-10 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-10 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-10 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-10 div.sk-label-container {text-align: center;}#sk-container-id-10 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-10 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-10\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GaussianNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" checked><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testset = OCTDataset(subset='test', transform=test_transform, device=device)\n",
        "testloader = DataLoader(testset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
        "print(len(testloader))\n",
        "\n",
        "# Test the classifier\n",
        "test_features, test_labels = [], []\n",
        "for inputs, labels in testloader:\n",
        "    test_features.extend(inputs.view(inputs.shape[0], -1).numpy())\n",
        "    test_labels.extend(labels.numpy())\n",
        "test_features, test_labels = np.array(test_features), np.array(test_labels)\n",
        "\n",
        "predicted_labels = clf.predict(test_features)\n",
        "\n",
        "balanced_accuracy = balanced_accuracy_score(test_labels, predicted_labels)\n",
        "f1 = f1_score(test_labels, predicted_labels, average='weighted')  # Use 'weighted' since we have imbalanced classes\n",
        "\n",
        "print(f'Balanced accuracy: {balanced_accuracy:.4f}')\n",
        "print(f'F1 score: {f1:.4f}')"
      ],
      "metadata": {
        "id": "Ms2XkKDpwD-w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59245986-7e1c-49e8-e039-edd9f5491218"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Balanced accuracy: 0.4955\n",
            "F1 score: 0.4967\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the confusion matrix\n",
        "cm = confusion_matrix(test_labels, predicted_labels)\n",
        "\n",
        "# Calculate the sensitivity (recall) for each class\n",
        "sensitivity = np.diag(cm) / np.sum(cm, axis=1)\n",
        "\n",
        "# Calculate the specificity for each class\n",
        "specificity = np.zeros(3)\n",
        "for i in range(3):\n",
        "    tp_fp = np.sum(cm[i, :])\n",
        "    tp_fn = np.sum(cm[:, i])\n",
        "    tp = cm[i, i]\n",
        "    tn = np.sum(cm) - tp_fp - tp_fn + tp\n",
        "    specificity[i] = tn / (tn + tp_fp - tp)\n",
        "\n",
        "# Calculate the separability (harmonic mean of sensitivity and specificity)\n",
        "separability = 2 * sensitivity * specificity / (sensitivity + specificity)\n",
        "\n",
        "print(\"\\nSensitivity (Recall):\")\n",
        "print(\"Class 0:\", sensitivity[0])\n",
        "print(\"Class 1:\", sensitivity[1])\n",
        "print(\"Class 2:\", sensitivity[2])\n",
        "\n",
        "print(\"\\nSeparability:\")\n",
        "print(\"Class 0:\", separability[0])\n",
        "print(\"Class 1:\", separability[1])\n",
        "print(\"Class 2:\", separability[2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rUfzjwF4jxOE",
        "outputId": "df5ca8cc-1b7c-49d8-9a6b-b65f331b9260"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sensitivity (Recall):\n",
            "Class 0: 0.23076923076923078\n",
            "Class 1: 0.675\n",
            "Class 2: 0.5806451612903226\n",
            "\n",
            "Separability:\n",
            "Class 0: 0.34615384615384615\n",
            "Class 1: 0.6450511945392491\n",
            "Class 2: 0.7054012608621572\n"
          ]
        }
      ]
    }
  ]
}