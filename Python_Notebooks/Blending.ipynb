{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "er0LOvqN_RaI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c1aadd2-4e84-4fa9-b652-a1515872b795"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import transforms\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import os\n",
        "import copy\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.kernel_approximation import RBFSampler\n",
        "from sklearn.metrics import balanced_accuracy_score, f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "import cv2\n",
        "from typing import List\n",
        "\n",
        "LABELS_Severity = {35: 0,\n",
        "                   43: 0,\n",
        "                   47: 1,\n",
        "                   53: 1,\n",
        "                   61: 2,\n",
        "                   65: 2,\n",
        "                   71: 2,\n",
        "                   85: 2}\n",
        "\n",
        "def normalize_np(image, mean, std):\n",
        "    grayscale_image = np.array(image.convert('L'))\n",
        "    return (grayscale_image - mean) / std\n",
        "\n",
        "mean = 0.1706\n",
        "std = 0.2112\n",
        "target_size = (224, 224) #(112, 112)\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize(size=target_size),\n",
        "    transforms.Lambda(lambda x: normalize_np(x, mean, std)),\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize(size=target_size),\n",
        "    transforms.Lambda(lambda x: normalize_np(x, mean, std)),\n",
        "])"
      ],
      "metadata": {
        "id": "RHMoUlkQ_cG8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LaplacianPyramidFusion:\n",
        "    def __init__(self, image_paths, levels=5, device='cuda:0'):\n",
        "        self.image_paths = image_paths\n",
        "        self.levels = levels\n",
        "        self.device = device\n",
        "\n",
        "    def read_images(self):\n",
        "        images = []\n",
        "        for path in self.image_paths:\n",
        "            img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
        "            img = torch.from_numpy(img).unsqueeze(0).unsqueeze(0).to(self.device)\n",
        "            images.append(img)        \n",
        "        return images      \n",
        "\n",
        "    def gaussian_pyramid(self, image):\n",
        "        image = image.float()  # Convert image to float32 format\n",
        "        g_pyr = [image]\n",
        "        for _ in range(self.levels-1):\n",
        "            image = torch.nn.functional.avg_pool2d(image, kernel_size=2, stride=2, padding=0)\n",
        "            # image = cv2.pyrDown(image)\n",
        "            g_pyr.append(image)\n",
        "        return g_pyr\n",
        "\n",
        "    def laplacian_pyramid(self, g_pyr):\n",
        "        l_pyr = [g_pyr[-1]]\n",
        "        for i in range(len(g_pyr)-1, 0, -1):\n",
        "            size = (g_pyr[i - 1].shape[2], g_pyr[i - 1].shape[1])\n",
        "            expanded = torch.nn.functional.interpolate(g_pyr[i], size=size, mode='bilinear', align_corners=False)\n",
        "            laplacian = g_pyr[i - 1] - expanded\n",
        "            l_pyr.append(laplacian)\n",
        "\n",
        "            # size = (g_pyr[i-1].shape[1], g_pyr[i-1].shape[0])\n",
        "            # expanded = cv2.pyrUp(g_pyr[i], dstsize=size)\n",
        "            # laplacian = cv2.subtract(g_pyr[i-1], expanded)\n",
        "            # l_pyr.append(laplacian)\n",
        "        return l_pyr[::-1]\n",
        "\n",
        "    def blend_pyramids(self, pyramids):\n",
        "        blended_pyr = []\n",
        "        for images in zip(*pyramids):\n",
        "            blended_img = torch.zeros_like(images[0], dtype=torch.float32)\n",
        "            # blended_img = np.zeros_like(images[0], dtype=np.float32)\n",
        "            for img in images:\n",
        "                blended_img += img\n",
        "                # blended_img += img.astype(np.float32)\n",
        "            blended_img /= len(images)\n",
        "            blended_pyr.append(blended_img)\n",
        "        return blended_pyr\n",
        "\n",
        "    def reconstruct_image(self, l_pyr):\n",
        "        image = l_pyr[-1]\n",
        "        for i in range(len(l_pyr) - 2, -1, -1):\n",
        "            size = (l_pyr[i].shape[2], l_pyr[i].shape[1])\n",
        "            expanded = torch.nn.functional.interpolate(image, size=size, mode='bilinear', align_corners=False)\n",
        "            image = expanded + l_pyr[i]\n",
        "        return image.squeeze().cpu().numpy().astype(np.uint8)\n",
        "\n",
        "        #     size = (l_pyr[i].shape[1], l_pyr[i].shape[0])\n",
        "        #     expanded = cv2.pyrUp(image, dstsize=size)\n",
        "        #     image = cv2.add(expanded, l_pyr[i])\n",
        "        # return image.astype(np.uint8)\n",
        "\n",
        "    def fuse(self):\n",
        "        images = self.read_images()\n",
        "        g_pyrs = [self.gaussian_pyramid(img) for img in images]\n",
        "        l_pyrs = [self.laplacian_pyramid(g_pyr) for g_pyr in g_pyrs]\n",
        "        blended_pyr = self.blend_pyramids(l_pyrs)\n",
        "        fused_image = self.reconstruct_image(blended_pyr)\n",
        "        return fused_image"
      ],
      "metadata": {
        "id": "dyxBbeWL_jq0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def blend_images(img1, img2, alpha):\n",
        "    # # Convert the images to the same size\n",
        "    # img1_resized = cv2.resize(img1, (img2.shape[1], img2.shape[0]))\n",
        "\n",
        "    # # Perform alpha blending\n",
        "    # blended = cv2.addWeighted(img1_resized, alpha, img2, 1 - alpha, 0)\n",
        "\n",
        "    #Try-2\n",
        "    # Convert the images to the same size\n",
        "    img2_resized = cv2.resize(img2, (img1.shape[1], img1.shape[0]))\n",
        "\n",
        "    # Ensure both images have the same number of dimensions\n",
        "    if len(img1.shape) != len(img2_resized.shape):\n",
        "        if len(img1.shape) == 3 and len(img2_resized.shape) == 2:\n",
        "            img1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
        "        elif len(img1.shape) == 2 and len(img2_resized.shape) == 3:\n",
        "            img2_resized = cv2.cvtColor(img2_resized, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Perform alpha blending\n",
        "    blended = cv2.addWeighted(img1, alpha, img2_resized, 1 - alpha, 0)\n",
        "\n",
        "    return blended\n",
        "\n",
        "# Add this function to combine edge-detected images\n",
        "def combine_edges(edges: List[np.ndarray]) -> np.ndarray:\n",
        "    combined = np.zeros_like(edges[0], dtype=np.uint8)\n",
        "    for edge in edges:\n",
        "        combined = cv2.addWeighted(combined, 1, edge, 1, 0)\n",
        "    return combined\n",
        "\n",
        "# Function to read image, apply Canny edge detection, and return the result\n",
        "def apply_canny_edge(image_path):\n",
        "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "    edges = cv2.Canny(img, 200, 500)\n",
        "    return edges\n",
        "\n",
        "# Function to create a grid image from a list of edge images\n",
        "# def create_grid_image(edge_images, grid_shape=(7, 7)):\n",
        "#     rows = []\n",
        "#     for r in range(grid_shape[0]):\n",
        "#         row = np.hstack(edge_images[r*grid_shape[1]:(r+1)*grid_shape[1]])\n",
        "#         rows.append(row)\n",
        "#     grid_image = np.vstack(rows)\n",
        "#     return grid_image\n",
        "def create_grid_image(edge_images, grid_shape=(7, 7), new_size=(64, 64)):\n",
        "    rows = []\n",
        "    for r in range(grid_shape[0]):\n",
        "        resized_images = []\n",
        "        for img in edge_images[r*grid_shape[1]:(r+1)*grid_shape[1]]:\n",
        "            resized_img = cv2.resize(img, new_size, interpolation=cv2.INTER_AREA)\n",
        "            resized_images.append(resized_img)\n",
        "        row = np.hstack(resized_images)\n",
        "        rows.append(row)\n",
        "    grid_image = np.vstack(rows)\n",
        "    return grid_image"
      ],
      "metadata": {
        "id": "bgcEBNs5vkcE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class OCTDataset(Dataset):\n",
        "    def __init__(self, annot=None, subset='train', transform=None, device='cpu'):\n",
        "        if subset == 'train':\n",
        "            self.annot = pd.read_csv(\"/content/drive/MyDrive/FML_Project/df_prime_train.csv\")\n",
        "        elif subset == 'test':\n",
        "            self.annot = pd.read_csv(\"/content/drive/MyDrive/FML_Project/df_prime_test.csv\")\n",
        "\n",
        "        # Extract \"Patient_ID\" and \"Week_Num\" columns\n",
        "        # print(\"Before Pairing \", len(self.annot))\n",
        "        self.patient_ids = self.annot[\"Patient_ID\"]\n",
        "        self.week_nums = self.annot[\"Week_Num\"]\n",
        "        self.patient_ids = self.annot[\"Patient_ID\"]\n",
        "        self.annot['Severity_Label'] = [LABELS_Severity[drss] for drss in copy.deepcopy(self.annot['DRSS'].values)]\n",
        "        self.drss_class = self.annot['Severity_Label']\n",
        "\n",
        "\n",
        "        # Create unique pairs of values\n",
        "        self.unique_pairs = set(zip(self.patient_ids, self.week_nums, self.drss_class))\n",
        "\n",
        "        # Print the unique pairs\n",
        "        # print(len(self.unique_pairs))\n",
        "        # for pair in self.unique_pairs:\n",
        "        #     print(pair)\n",
        "\n",
        "        self.root = os.path.expanduser(\"/content/drive/MyDrive/FML_Project/\")\n",
        "        self.transform = transform\n",
        "        self.nb_classes=len(np.unique(list(LABELS_Severity.values())))\n",
        "        self.path_list = self.annot['File_Path'].values\n",
        "\n",
        "        self._labels = [pair[2] for pair in self.unique_pairs]\n",
        "        # self._labels = self.annot['Severity_Label'].values\n",
        "        assert len(self.unique_pairs) == len(self._labels)\n",
        "        \n",
        "        max_samples = int(len(self._labels)) #32 #int(len(self._labels)/2)\n",
        "        self.max_samples = max_samples\n",
        "        self.device = device\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # Get the Patient_ID and Week_Num from the indexed element in unique_pairs\n",
        "        patient_id, week_num, target = list(self.unique_pairs)[index]\n",
        "\n",
        "        # Filter the annot DataFrame to select rows that match the Patient_ID and Week_Num\n",
        "        filtered_df = self.annot[(self.annot['Patient_ID'] == patient_id) & (self.annot['Week_Num'] == week_num)]\n",
        "\n",
        "        # Extract the file paths from the filtered DataFrame and return them as a list\n",
        "        # file_paths = filtered_df['File_Path'].values.tolist()\n",
        "        file_paths = [self.root + file_path for file_path in filtered_df['File_Path'].values.tolist()]\n",
        "        output_dir = os.path.dirname(file_paths[0])\n",
        "\n",
        "        # LaplacianPyramidFusion\n",
        "        #fusion = LaplacianPyramidFusion(file_paths)\n",
        "        #fused_image = fusion.fuse()\n",
        "        #cv2.imwrite(os.path.join(output_dir, f\"fused_image_level_5.jpg\"), fused_image)\n",
        "        #print(\"fused op:\"+os.path.join(output_dir, f\"fused_image_level_5.jpg\"))\n",
        "\n",
        "        # Alpha blending\n",
        "        # Blend the images sequentially\n",
        "        # blended = cv2.imread(file_paths[0], cv2.IMREAD_UNCHANGED)\n",
        "        # for i in range(1, len(file_paths)):\n",
        "        #     alpha = 1 - (i / len(file_paths)) # more weightage to first image encountered\n",
        "        #     alpha = 1 / len(file_paths) #equal weightage for each image\n",
        "        #     next_image = cv2.imread(file_paths[i], cv2.IMREAD_UNCHANGED)\n",
        "        #     blended = blend_images(blended, next_image, alpha)\n",
        "        # output_filename = f'ab_final.png'\n",
        "        # output_filepath = os.path.join(output_dir, output_filename)\n",
        "        # print(\"alpha op:\"+output_filepath)\n",
        "        # cv2.imwrite(output_filepath, blended)\n",
        "\n",
        "        # Canny edges\n",
        "        # Apply the Canny edge detection on each image in file_paths and store the results in a list\n",
        "        # Check this path for other combinations:\n",
        "        # /content/drive/MyDrive/FML_Project//Prime_FULL/01-027/W52/OS/cn_final_200_700.jpg\n",
        "        # Optimal based on visual inspection: 200_500\n",
        "        edge_images = [cv2.Canny(cv2.imread(file_path, cv2.IMREAD_GRAYSCALE), 300, 700) for file_path in file_paths]\n",
        "        combined_edges = combine_edges(edge_images)\n",
        "        output_filename = f'cn_trial_300_700.jpg'\n",
        "        output_filepath = os.path.join(output_dir, output_filename)\n",
        "        print(\"canny op:\"+output_filepath)\n",
        "        cv2.imwrite(output_filepath, combined_edges)\n",
        "\n",
        "        # Sobel operator\n",
        "        # Apply the Sobel-Scharr on each image in file_paths and store the results in a list\n",
        "        # Check this path for other combinations:\n",
        "        # /content/drive/MyDrive/FML_Project//Prime_FULL/01-027/W52/OS/cn_final_200_700.jpg\n",
        "        # Optimal based on visual inspection: 200_500\n",
        "        # edge_images = []\n",
        "        # for file_path in file_paths:\n",
        "        #     image = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)\n",
        "        #     #10,01-\n",
        "        #     scharr_x = cv2.Scharr(image, cv2.CV_64F, 0, 1)\n",
        "        #     scharr_y = cv2.Scharr(image, cv2.CV_64F, 0, 1)\n",
        "\n",
        "        #     # Combine x and y gradients\n",
        "        #     scharr = cv2.addWeighted(scharr_x, 0.5, scharr_y, 0.5, 0)\n",
        "        #     # Convert to uint8 to have a similar range as Canny\n",
        "        #     scharr = cv2.convertScaleAbs(scharr)\n",
        "        #     edge_images.append(scharr)\n",
        "        # combined_edges = combine_edges(edge_images)\n",
        "        # output_filename = f'sobel_trial.jpg'\n",
        "        # output_filepath = os.path.join(output_dir, output_filename)\n",
        "        # print(\"Sobel op:\"+output_filepath)\n",
        "        # cv2.imwrite(output_filepath, combined_edges)\n",
        "\n",
        "        # Canny edge on fusion image level 5\n",
        "        # fused_image_l5_path = os.path.join(output_dir, f\"fused_image_level_5.jpg\")\n",
        "        # fused_edge_image_l5 = cv2.Canny(cv2.imread(fused_image_l5_path, cv2.IMREAD_GRAYSCALE), 200, 500)\n",
        "        # output_filename = f'fused_edge_image_l5.jpg'\n",
        "        # output_filepath = os.path.join(output_dir, output_filename)\n",
        "        # print(\"Canny edge on fusion image level 5 op:\"+output_filepath)\n",
        "        # cv2.imwrite(output_filepath, fused_edge_image_l5)        \n",
        "\n",
        "        # Canny edge on alpha blended image\n",
        "        # ab_image_path = os.path.join(output_dir, f\"ab_final.png\")\n",
        "        # ab_edge_image = cv2.Canny(cv2.imread(ab_image_path, cv2.IMREAD_GRAYSCALE), 200, 500)\n",
        "        # output_filename = f'ab_edge_image.jpg'\n",
        "        # output_filepath = os.path.join(output_dir, output_filename)\n",
        "        # print(\"Canny edge on alpha blended image op:\"+output_filepath)\n",
        "        # cv2.imwrite(output_filepath, ab_edge_image)   \n",
        "\n",
        "        # Create 7x7 grid - plain - image\n",
        "        # Sort image paths by file name in ascending order\n",
        "        # sorted_image_paths = sorted(file_paths, key=lambda x: int(os.path.splitext(os.path.basename(x))[0]))\n",
        "        # #print(sorted_image_paths)\n",
        "        # # print(os.path.join(output_dir, f\"grid_image.jpg\"))\n",
        "        # # Apply Canny edge detection on each sorted image\n",
        "        # sorted_images = [cv2.imread(image_path, cv2.IMREAD_GRAYSCALE) for image_path in sorted_image_paths]\n",
        "\n",
        "        # # Calculate the number of placeholder images needed\n",
        "        # num_placeholders = 49 - len(sorted_images)\n",
        "\n",
        "        # # Create black background placeholder images and add them to sorted_images\n",
        "        # if num_placeholders > 0:\n",
        "        #     # Determine the size of the placeholder image based on the first image in the sorted_images list\n",
        "        #     placeholder_size = sorted_images[0].shape if sorted_images else (64, 64)  # Assuming 64x64 if no images are found\n",
        "            \n",
        "        #     for _ in range(num_placeholders):\n",
        "        #         placeholder_image = np.zeros(placeholder_size, dtype=np.uint8)\n",
        "        #         sorted_images.append(placeholder_image)\n",
        "\n",
        "        # # Create a 7x7 grid image\n",
        "        # grid_image = create_grid_image(sorted_images, grid_shape=(7, 7))\n",
        "        # # Save the grid image\n",
        "        # cv2.imwrite(os.path.join(output_dir, f\"grid_image.jpg\"), grid_image)\n",
        "\n",
        "\n",
        "        # # Create 7x7 grid - canny - image\n",
        "        # # Sort image paths by file name in ascending order\n",
        "        # sorted_image_paths = sorted(file_paths, key=lambda x: int(os.path.splitext(os.path.basename(x))[0]))\n",
        "        # #print(sorted_image_paths)\n",
        "        # # print(os.path.join(output_dir, f\"grid_image_canny.jpg\"))\n",
        "        # # Apply Canny edge detection on each sorted image\n",
        "        # sorted_edge_images = [apply_canny_edge(image_path) for image_path in sorted_image_paths]\n",
        "\n",
        "        # # Calculate the number of placeholder images needed\n",
        "        # num_placeholders = 49 - len(sorted_edge_images)\n",
        "\n",
        "        # # Create black background placeholder images and add them to sorted_edge_images\n",
        "        # if num_placeholders > 0:\n",
        "        #     # Determine the size of the placeholder image based on the first image in the sorted_edge_images list\n",
        "        #     placeholder_size = sorted_edge_images[0].shape if sorted_edge_images else (64, 64)  # Assuming 64x64 if no images are found\n",
        "            \n",
        "        #     for _ in range(num_placeholders):\n",
        "        #         placeholder_image = np.zeros(placeholder_size, dtype=np.uint8)\n",
        "        #         sorted_edge_images.append(placeholder_image)\n",
        "\n",
        "\n",
        "        # # Create a 7x7 grid image\n",
        "        # grid_image = create_grid_image(sorted_edge_images, grid_shape=(7, 7))\n",
        "        # # Save the grid image\n",
        "        # cv2.imwrite(os.path.join(output_dir, f\"grid_image_canny.jpg\"), grid_image)\n",
        "\n",
        "        # print(\"File paths of \", patient_id, \" , \", week_num, str(file_paths))\n",
        "        # print(type(img), type(img_gray))\n",
        "\n",
        "        if self.transform is not None:\n",
        "            img_gray = self.transform(Image.fromarray(combined_edges))\n",
        "\n",
        "        return img_gray, target\n",
        "\n",
        "    def __len__(self):\n",
        "        if self.max_samples is not None:\n",
        "            return min(len(self._labels), self.max_samples)\n",
        "        else:\n",
        "            return len(self._labels)"
      ],
      "metadata": {
        "id": "w8ZJTmkJ_vAP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print('Found device', device)\n",
        "batch_size = 32\n",
        "\n",
        "trainset = OCTDataset(subset='train', transform=train_transform, device=device)\n",
        "testset = OCTDataset(subset='test', transform=test_transform, device=device)\n",
        "\n",
        "train_loader = DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(testset, batch_size=batch_size, shuffle=True)\n",
        "print(len(trainset), len(testset))\n",
        "\n",
        "# for i in range(len(trainset)):\n",
        "#   print(trainset[i][0].shape)\n",
        "#   print(\"Train fusion done:\", i)\n",
        "\n",
        "# for i in range(len(testset)):\n",
        "#   print(testset[i][0].shape)\n",
        "#   print(\"Test fusion done:\", i)\n",
        "\n",
        "print(trainset[1][0].shape)\n"
      ],
      "metadata": {
        "id": "xsr39fhrBVsO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e1a6bb4-2a42-4e0f-afbf-be14ebacbb55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found device cuda:0\n",
            "495 163\n",
            "canny op:/content/drive/MyDrive/FML_Project//Prime_FULL/01-027/W52/OS/cn_trial_300_700.jpg\n",
            "(224, 224)\n"
          ]
        }
      ]
    }
  ]
}